# Training Configuration for Semantic-STGCNN
# This file contains the default training configuration parameters

# Model architecture parameters
model:
  name: "semantic_stgcnn"
  n_stgcnn: 2                    # Number of ST-GCN layers
  n_txpcnn: 5                    # Number of temporal prediction CNN layers
  input_feat: 21                 # Number of input features (with semantic features)
  output_feat: 2                 # Number of output features (x, y coordinates)
  seq_len: 8                     # Length of input sequence
  pred_seq_len: 12               # Length of prediction sequence
  kernel_size: 3                 # Temporal kernel size
  use_mdn: false                 # Whether to use Mixture Density Networks
  dropout: 0.1                   # Dropout rate
  residual: true                 # Whether to use residual connections

# Training parameters
training:
  batch_size: 32                 # Batch size for training
  learning_rate: 0.001           # Initial learning rate
  num_epochs: 100                # Number of training epochs
  weight_decay: 0.0001           # Weight decay for regularization
  grad_clip: 1.0                 # Gradient clipping threshold
  
  # Early stopping configuration
  early_stopping:
    patience: 10                 # Early stopping patience
    min_delta: 0.0001           # Minimum improvement threshold
  
  # Learning rate scheduler
  scheduler:
    type: "StepLR"              # Learning rate scheduler type
    step_size: 30               # Step size for StepLR
    gamma: 0.1                  # Decay factor for StepLR
  
  # Optimizer configuration
  optimizer:
    type: "Adam"                # Optimizer type
    betas: [0.9, 0.999]         # Adam beta parameters
    eps: 0.00000001             # Adam epsilon parameter

# Dataset parameters
dataset:
  name: "sdd"                   # Dataset name
  data_dir: "./DATASET/SDD_WITH_FEATURES_SPLITTED"  # Path to dataset
  obs_len: 8                    # Number of observed time steps
  pred_len: 12                  # Number of predicted time steps
  skip: 1                       # Number of frames to skip
  threshold: 0.002              # Threshold for non-linear trajectory detection
  min_ped: 1                    # Minimum number of pedestrians per sequence
  delim: "tab"                  # Delimiter in dataset files
  norm_lap_matr: true           # Whether to use normalized Laplacian matrix
  
  # Data augmentation (disabled by default for training)
  augmentation:
    enabled: false              # Whether to use data augmentation
    rotation: [-0.1, 0.1]       # Rotation angles for augmentation
    translation: [[-0.5, 0.5], [-0.5, 0.5]]  # Translation ranges
    noise: 0.01                 # Noise standard deviation

# Loss function parameters
loss:
  type: "bivariate"             # Loss function type
  smoothness_weight: 0.1        # Weight for smoothness penalty
  distance_weight: 0.1          # Weight for distance penalty
  linearity_weight: 0.05       # Weight for linearity penalty

# Evaluation parameters
evaluation:
  metrics: ["ade", "fde"]       # Evaluation metrics to compute
  save_predictions: true        # Whether to save predictions
  visualize: false              # Whether to create visualizations during training

# Data loading parameters
dataloader:
  num_workers: 4                # Number of data loader workers
  pin_memory: true              # Whether to pin memory
  shuffle_train: true           # Whether to shuffle training data
  shuffle_val: false            # Whether to shuffle validation data
  drop_last: true               # Whether to drop last incomplete batch

# Logging and monitoring
logging:
  level: "INFO"                 # Logging level
  log_dir: "./logs"             # Directory for log files
  log_interval: 10              # Logging interval (batches)
  save_interval: 1000           # Checkpoint saving interval (batches)
  tensorboard: true             # Whether to use TensorBoard logging

# Output and checkpointing
output:
  output_dir: "./outputs"       # Output directory for results
  checkpoint_dir: "./checkpoints"  # Directory for saving checkpoints
  save_best_only: true          # Whether to save only the best model
  save_last: true               # Whether to save the last model

# Hardware and performance
hardware:
  device: "auto"                # Device to use (cpu, cuda, auto)
  mixed_precision: false        # Whether to use mixed precision training
  compile_model: false          # Whether to compile model (PyTorch 2.0+)

# Reproducibility
reproducibility:
  seed: 42                      # Random seed
  deterministic: true           # Whether to use deterministic algorithms
  benchmark: false              # Whether to use cudnn benchmark

# Semantic features
semantic:
  enabled: true                 # Whether to use semantic features
  feature_dim: 17               # Dimension of semantic features
  semantic_map_dir: "./DATASET/SDD_semantic_maps_CORRECTED"
  normalize_features: true      # Whether to normalize semantic features

# Graph construction
graph:
  adjacency_type: "inverse_distance"  # Type of adjacency matrix
  normalize_adjacency: true     # Whether to normalize adjacency matrix
  self_loops: false             # Whether to include self loops
  directed: false               # Whether graph is directed

# Visualization parameters (for training monitoring)
visualization:
  plot_trajectories: false      # Whether to plot trajectories during training
  plot_predictions: false       # Whether to plot predictions during training
  plot_attention: false         # Whether to plot attention weights
  save_plots: false             # Whether to save plots during training
  plot_format: "png"            # Format for saved plots
  dpi: 300                      # DPI for saved plots
